{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "from rasterio.merge import merge\n",
    "import matplotlib.pyplot as plt\n",
    "from pyproj import CRS\n",
    "import flopy\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge `dis` and `hds` data into single raster coverage from the two parent models that overlap the Neversink domain:\n",
    "- 0108_0110_0202_0203_MF6_SS_Unconfined_250\n",
    "- 0204_0206_0209_MF6_SS_Unconfined_250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = '../parent_model/mfexport_outfiles'\n",
    "\n",
    "parent_models = [\n",
    "    '0108_0110_0202_0203_MF6_SS_Unconfined_250',\n",
    "    '0204_0206_0209_MF6_SS_Unconfined_250'\n",
    "]\n",
    "\n",
    "packages = os.listdir(os.path.join(data_root, parent_models[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = '../parent_model/merged_parent_output'\n",
    "\n",
    "if not os.path.exists(out_path):\n",
    "    os.makedirs(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_raster_data_merge(data_root, out_path, parent_models, packages):    \n",
    "    #  get list of tif files from the models to merge\n",
    "    for pkg in packages:    \n",
    "\n",
    "        print('Now merging {} package data'.format(pkg))\n",
    "        package_tifs = []\n",
    "\n",
    "        for root, dirs, files in os.walk(os.path.join(data_root, parent_models[0], pkg)):\n",
    "            for file in files:\n",
    "                if file.endswith('.tif'):\n",
    "                    package_tifs.append(file)\n",
    "\n",
    "        for tif in package_tifs:\n",
    "            src_files_to_merge = []\n",
    "            for model in parent_models:\n",
    "                file_path = os.path.join(data_root, model, pkg, 'rasters', tif)\n",
    "                \n",
    "                #  open file in read mode w/rasterio and make a list of files to merge\n",
    "                src = rasterio.open(file_path)\n",
    "                src_files_to_merge.append(src)\n",
    "\n",
    "            #  define nondata value by layer\n",
    "            if tif.startswith('idomain'):\n",
    "                nodata = 0\n",
    "            elif tif.startswith(('hds', 'wt')):\n",
    "                nodata = np.nan\n",
    "            else:\n",
    "                nodata = -2.14748365e+09\n",
    "            print('nodata value: {}'.format(nodata))\n",
    "            \n",
    "            #  perform merge with rasterio.merge.merge\n",
    "            mosaic, out_trans = merge(src_files_to_merge, nodata=nodata)\n",
    "            print('merged: {}'.format(tif))\n",
    "            \n",
    "            #  plot merged layer to make sure that it looks right\n",
    "            plot_mosaic = mosaic.copy()\n",
    "            if not tif.startswith('idomain'):\n",
    "                plot_mosaic[plot_mosaic==nodata] = np.nan\n",
    "            plt.figure(figsize=(6, 6))\n",
    "            plt.imshow(plot_mosaic[0])\n",
    "            plt.colorbar()\n",
    "            #plt.show()\n",
    "            \n",
    "            #  update the metadata with new dimensions, transform and CRS. Also add compression 'lzw'\n",
    "            out_meta = src.meta.copy()\n",
    "            out_meta.update({'driver': 'GTiff',\n",
    "                     'height': mosaic.shape[1],\n",
    "                     'width': mosaic.shape[2],\n",
    "                     'transform': out_trans,\n",
    "                     'compress': 'lzw',  # see if this works or not...\n",
    "                     'crs': '+datum=WGS84 +lat_0=23 +lat_1=29.5 +lat_2=45.5 +lon_0=-96 +no_defs +proj=aea +units=m +x_0=0 +y_0=0'\n",
    "                     }\n",
    "                    )\n",
    "\n",
    "            #  write mosaic to out_path\n",
    "            out_fp = os.path.join(out_path, (tif[:-4] + '_merged.tif'))\n",
    "\n",
    "            with rasterio.open(out_fp, \"w\", **out_meta) as dest:\n",
    "                dest.write(mosaic)\n",
    "            \n",
    "            print('wrote file: {}'.format(out_fp))\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_raster_data_merge(data_root, out_path, parent_models, packages)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the merged head file to binary format using `flopy.utils`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ws = os.path.join(out_path, 'parent_mf_nwt')\n",
    "'''\n",
    "if os.path.exists(model_ws):\n",
    "    shutil.rmtree(model_ws)\n",
    "    \n",
    "os.mkdir(model_ws)\n",
    "'''    \n",
    "precision = 'double' # or 'double'\n",
    "dtype = np.float64 # or np.float64\n",
    "\n",
    "mf = flopy.modflow.Modflow(modelname='ngwm_parent',model_ws=model_ws)\n",
    "dis = flopy.modflow.ModflowDis(mf, nlay=nlay, nrow=nrow, ncol=ncol, delr=delr, delc=delc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hds_tif = 'hds_lay0_per0_stp0_merged.tif'\n",
    "hds_dir = '../parent_model/merged_parent_output'\n",
    "hds_path = os.path.join(hds_dir, hds_tif)\n",
    "\n",
    "with rasterio.open(hds_path) as src:\n",
    "    data = np.squeeze(src.read())\n",
    "    \n",
    "    \n",
    "plt.imshow(data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "replace `nan` nodata with -9999 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[np.isnan(data)] = -9999\n",
    "plt.imshow(data)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'head'\n",
    "\n",
    "# write a binary data file\n",
    "pertim = dtype(1.0)\n",
    "header = flopy.utils.BinaryHeader.create(bintype=text, precision=precision,\n",
    "                                         text=text, nrow=nrow, ncol=ncol,\n",
    "                                         ilay=1, pertim=pertim,\n",
    "                                         totim=pertim, kstp=1, kper=1)\n",
    "pth = os.path.join(model_ws, 'ngwm_parent.hds')\n",
    "flopy.utils.Util2d.write_bin(data.shape, pth, data, header_data=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf.write_input()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### write a fake CBC file to make mfsetup happy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pth.replace('hds','cbc'), 'w') as ofp:\n",
    "    ofp.write('This is not the file you are looking for \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check out timesteps\n",
    "\n",
    "This issue was resolved by adding `copy_stress_periods: 'all'` to the parent block of the YML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# source data\n",
    "headfile = self.hpth\n",
    "vmin, vmax = -1e30, 1e30,\n",
    "check_source_files([headfile])\n",
    "hdsobj = bf.HeadFile(headfile) #, precision='single')\n",
    "all_kstpkper = hdsobj.get_kstpkper()\n",
    "\n",
    "# get the last timestep in each stress period if there are more than one\n",
    "#kstpkper = []\n",
    "#unique_kper = []\n",
    "#for (kstp, kper) in all_kstpkper:\n",
    "# if kper not in unique_kper:\n",
    "# kstpkper.append((kstp, kper))\n",
    "# unique_kper.append(kper)\n",
    "last_steps = {kper: kstp for kstp, kper in all_kstpkper}\n",
    " \n",
    " #assert len(unique_kper) == len(set(self.copy_stress_periods)), \\\n",
    " #\"read {} from {},\\nexpected stress periods: {}\".format(kstpkper,\n",
    " # headfile,\n",
    " \n",
    " '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdobj = flopy.utils.binaryfile.HeadFile(pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_kstpkper = hdobj.get_kstpkper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_steps = {kper: kstp for kstp, kper in all_kstpkper}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf.dis.nstp.array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf.dis.nper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for inset_per, parent_per in self.inset_parent_period_mapping.items():"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### update `nam` file with spatial reference information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "establish relevant information for parent `.nam` file spatial reference header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_dir = '../parent_model/merged_parent_output/'\n",
    "file_name = 'idomain_lay0_merged.tif'\n",
    "input_file = os.path.join(merge_dir, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(input_file) as src:\n",
    "    meta = src.meta\n",
    "    bounds = src.bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncol = meta['width']\n",
    "nlay = meta['count']\n",
    "nrow = meta['height']\n",
    "delc = meta['transform'][0]\n",
    "delr = -meta['transform'][4]\n",
    "length_units = 'meters'\n",
    "\n",
    "# parent grid?\n",
    "xoff = bounds[0]\n",
    "yoff = bounds[1]\n",
    "#  coord ref doesn't match epsg code\n",
    "proj_string = CRS(meta['crs']).to_proj4()\n",
    "wkt_string = CRS(meta['crs']).to_wkt()\n",
    "\n",
    "print('ncol: {0}, nlay: {1}, nrow: {2}, delc: {3}, delr: {4}, length_units: {5}, xoff: {6}, yoff: {7}'.format(ncol, nlay, nrow, delc, delr, length_units, xoff, yoff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### re-write name file header to include spatial reference information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nam= [i.strip() for i in open(os.path.join(model_ws,'ngwm_parent.nam'), 'r').readlines() if '#' not in i]\n",
    "print (nam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headerline = ''.join(['#parent nam file just for reading in hds info\\n',\n",
    "      '#xll:{0}; yll:{1}; rotation:0; proj4_str:{2}; units:meters; lenuni:2;  ;start_datetime:1-1-2011'.format(\n",
    "      xoff, yoff, '+init=epsg:5070')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headerline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(model_ws,'ngwm_parent.nam'), 'w') as ofp:\n",
    "    ofp.write('{}\\n'.format(headerline))\n",
    "    [ofp.write('{}\\n'.format(line)) for line in nam]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
