{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../python_packages_static/')\n",
    "import flopy as fp\n",
    "import pyemu\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os, shutil, glob, sys\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PEST setup\n",
    "This notebook reads in the existing MF6 model built using modflow-setup with the script `../scripts/setup_model.py`. This notebook makes extensive use of the `PstFrom` functionality in `pyemu` to set up multipliers on parameters. There are a few custom parameterization steps as well.  \n",
    "\n",
    "Observations are also defined, assigned initial values, and weights based on preliminary assumptions about error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyemu.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define locations and other global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_ws = '../neversink_mf6/' # folder containing the MODFLOW6 files\n",
    "template_ws = '../run_data'  # folder to create and write the PEST setup to\n",
    "noptmax0_dir = '../noptmax0_testing/' # folder in which to write noptmax=0 test run version of PST file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### kill the `original` folder (a relic from the mfsetup process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(sim_ws,'original')):\n",
    "    shutil.rmtree(os.path.join(sim_ws,'original'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_MF6 = True # option to run MF6 to generate output but not needed if already been run in sim_ws\n",
    "cdir = os.getcwd()\n",
    "\n",
    "\n",
    "# optionally run MF6 to generate model output\n",
    "if run_MF6:\n",
    "    os.chdir(sim_ws)\n",
    "    os.system('mf6')\n",
    "    os.chdir(cdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create land surface observations we will need at the end\n",
    "These will be used as inequality observations (less than) to enforce that heads should not exceed the model top. Option for spatial frequency is set below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irch_file = f'{sim_ws}/irch.dat'    # file with the highest active layer identified\n",
    "id3_file = f'{sim_ws}/idomain_003.dat' # deepest layer idomain - gives the maximum lateral footprint\n",
    "top_file = f'{sim_ws}/top.dat'     # the model top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = np.loadtxt(top_file)\n",
    "top[top<-8000] = np.nan\n",
    "plt.imshow(top)\n",
    "\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id3  = np.loadtxt(id3_file, dtype=int)\n",
    "plt.imshow(id3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irch = np.loadtxt(irch_file, dtype=int) \n",
    "irch -= 1 # note that this is 1-based, not 0-based because it's a MF6 file\n",
    "plt.imshow(irch)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set frequency for land surface observations lateralls, in model cells\n",
    "lsobs_every_n_cells = 50 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a grid of cells spaced at the spacing suggested above\n",
    "nrow, ncol = id3.shape\n",
    "j = list(range(ncol))[0:ncol:lsobs_every_n_cells]\n",
    "i = list(range(nrow))[0:nrow:lsobs_every_n_cells]\n",
    "J,I = np.meshgrid(j,i)\n",
    "points = list(zip(I.ravel(),J.ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now keep only those that are in active cells (using ibound of layer4 as the basis) and drop a few others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_points = [(irch[i,j],i,j) for i,j in points if id3[i,j]==1]\n",
    "drop_points = [(0, 150, 50),(3, 150, 100),(3, 100, 50)]\n",
    "keep_points = [i for i in keep_points if i not in drop_points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make list of indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(sim_ws,'land_surf_obs-indices.csv'), 'w') as ofp:\n",
    "    ofp.write('k,i,j,obsname\\n')\n",
    "    [ofp.write('{0},{1},{2},land_surf_obs_{1}_{2}\\n'.format(*i)) for i in keep_points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make an observations file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(sim_ws,'land_surf_obs-observations.csv'), 'w') as ofp:\n",
    "    ofp.write('obsname,obsval\\n')\n",
    "    [ofp.write('land_surf_obs_{1}_{2},{3}\\n'.format(*i, top[i[1],i[2]])) for i in keep_points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start setting up the `PstFrom` object to create PEST inputs\n",
    "### load up the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = fp.mf6.MFSimulation.load(sim_ws=sim_ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = sim.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually create a spatial reference object from the grid.json metadata\n",
    "# this file created by modflow-setup\n",
    "grid_data = json.load(open(os.path.join(sim_ws,'neversink_grid.json')))\n",
    "sr_model = pyemu.helpers.SpatialReference(delr=grid_data['delr'],\n",
    "                                           delc=grid_data['delc'],\n",
    "                                           rotation= grid_data['angrot'],\n",
    "                                           epsg = grid_data['epsg'],\n",
    "                                           xul = grid_data['xul'],\n",
    "                                           yul = grid_data['yul'],\n",
    "                                           units='meters',\n",
    "                                           lenuni=grid_data['lenuni'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the PstFrom object \n",
    "pf = pyemu.utils.PstFrom(original_d=sim_ws, new_d=template_ws,\n",
    "                 remove_existing=True,\n",
    "                 longnames=True, spatial_reference=sr_model,\n",
    "                 zero_based=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## we will parameterize....\n",
    "- pilot points for k, k33, r\n",
    "- zones for l, k33, r\n",
    "- constant for R\n",
    "- sfr conductance by reach\n",
    "- well pumping \n",
    "- CHDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parameterize list-directed well and chd packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_tags = {'wel_':[.8,1.2], 'chd_':[.8,1.2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tag,bnd in list_tags.items():\n",
    "    lb,ub = bnd\n",
    "    filename = os.path.basename(glob.glob(os.path.join(template_ws, '*{}*'.format(tag)))[0])\n",
    "    pf.add_parameters(filenames=filename, par_type = 'grid',\n",
    "                     upper_bound=ub, lower_bound=lb, par_name_base=tag,\n",
    "                     index_cols=[0,1,2], use_cols=[3],pargp=tag[:-1],alt_inst_str='',\n",
    "                     comment_char='#')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## now set up pilot points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_ub = 152 # ultimate upper bound on K\n",
    "# set up pilot points\n",
    "pp_tags = {'k':[.01,10.,k_ub], 'k33':[.01,10.,k_ub/10]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we will use idomain to define zones for pilot points as going in active areas of each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idm = m.dis.idomain.array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(idm[2])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idm[idm==-1]=0 # make pass through cells (e.g. idomain==-1) the same as inactive (e.g. idomain == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    plt.figure()\n",
    "    plt.imshow(idm[i])\n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### before setting up K, need to edit the zone files to only have nonzero values in active cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kzonefile = '../processed_data/padded_L{}_K_Zone_50mGrid.dat'\n",
    "zonearrs = {}\n",
    "for i in range(m.dis.nlay.data):\n",
    "    kz = np.loadtxt(kzonefile.format(i)).astype(int)\n",
    "    kz[idm[i] != 1] = 0 \n",
    "    zonearrs[i] = kz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    plt.figure()\n",
    "    plt.imshow(zonearrs[i])\n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick take a look at unique zones present in each layer\n",
    "[np.unique(kz) for _,kz in zonearrs.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set up for K\n",
    "for tag,bnd in pp_tags.items():\n",
    "    lb, ub, ultub = bnd\n",
    "    if tag == 'k':\n",
    "        arrfiles = sorted([f for f in os.listdir(template_ws) if f.startswith(tag) & ('k33' not in f)])\n",
    "    else:\n",
    "        arrfiles = sorted([f for f in os.listdir(template_ws) if f.startswith(tag)])\n",
    "    \n",
    "    for arr_file in arrfiles:        \n",
    "        currlay = int(re.findall('\\d+',arr_file.replace('k33',''))[-1])\n",
    "        \n",
    "        # pilot points\n",
    "        # set pilot point spacing: NB every 5 cells in the smaller-zone layers, and every 20 cells in others\n",
    "        if currlay in [1,2]:\n",
    "            pp_space = 5           \n",
    "        else: \n",
    "            pp_space = 20\n",
    "        v = pyemu.utils.geostats.ExpVario(a=sr_model.delr[0]*3*pp_space,contribution=1.0)\n",
    "        gs = pyemu.utils.geostats.GeoStruct(variograms=v,nugget=0.0, transform='log')\n",
    "\n",
    "        print('pps for layer {} --- filename: {}: idomain_sum: {}'.format(currlay, arr_file, idm[currlay].sum()))\n",
    "        pf.add_parameters(filenames=arr_file, par_type='pilotpoints', pp_space=pp_space,\n",
    "                         upper_bound=ub, lower_bound=lb, geostruct=gs,\n",
    "                         par_name_base='{}_pp'.format(tag),alt_inst_str='',\n",
    "                         zone_array=idm[currlay], pargp='pp_{}'.format(tag),\n",
    "                         ult_ubound=ultub)\n",
    "        # zones\n",
    "        print('zones for layer {} --- filename: {}: idomain_sum: {}'.format(currlay, arr_file, idm[currlay].sum()))\n",
    "        pf.add_parameters(filenames=arr_file, par_type='zone',alt_inst_str='',\n",
    "                         zone_array = zonearrs[currlay],lower_bound=lb,upper_bound=ub,\n",
    "                         pargp='zn_{}'.format(tag), par_name_base='{}_{}'.format(tag,currlay),\n",
    "                          ult_ubound=ultub)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recharge as special case because no idomain for R\n",
    "rtags= {'rch':[0.8,1.2, np.max(m.rch.recharge.array)*1.2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tag,bnd in rtags.items():\n",
    "    lb, ub, ultub = bnd\n",
    "    if tag == 'k':\n",
    "        arrfiles = sorted([f for f in os.listdir(template_ws) if f.startswith(tag) & ('k33' not in f)])\n",
    "    else:\n",
    "        arrfiles = sorted([f for f in os.listdir(template_ws) if f.startswith(tag)])\n",
    "    \n",
    "    for arr_file in arrfiles:\n",
    "        # pilot points\n",
    "        pf.add_parameters(filenames=arr_file, par_type='pilotpoints', pp_space=pp_space,\n",
    "                         upper_bound=ub, lower_bound=lb, geostruct=gs,\n",
    "                         par_name_base='{}_pp'.format(tag),\n",
    "                          zone_array=idm[3],alt_inst_str='',\n",
    "                         pargp='pp_{}'.format(tag),\n",
    "                          ult_ubound=ultub)\n",
    "        # constant\n",
    "        pf.add_parameters(filenames=arr_file, par_type='constant',\n",
    "                 upper_bound=ub-0.1, lower_bound=lb+0.1, \n",
    "                 par_name_base='{}_const'.format(tag),\n",
    "                 zone_array=idm[3],alt_inst_str='',\n",
    "                 pargp='pp_{}'.format(tag),\n",
    "                           ult_ubound=ultub)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the `build_pst` method compiles all the parameters we've added and makes a `Pst` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst = pf.build_pst('tmp.pst')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a TPL file for SFR and add it to the `pst` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfrfilename = 'neversink_packagedata.dat'\n",
    "\n",
    "print('working on {}'.format(sfrfilename))\n",
    "# read in and strip and split the input lines\n",
    "insfr = [line.strip().split() for line in open(os.path.join(template_ws,sfrfilename), 'r').readlines() if '#' not in line]\n",
    "headerlines = [line.strip() for line in open(os.path.join(template_ws,sfrfilename), 'r').readlines() if '#' in line]\n",
    "\n",
    "# set up the template line strings by segment\n",
    "tpl_char = ['~ sfrk_{} ~'.format(line[-1]) for line in insfr]\n",
    "\n",
    "# stick the tpl text in the K column. NB -> gotta count from the end because of \n",
    "# the possibility of NONE or i,j,k as indexing\n",
    "for line,tpl in zip(insfr,tpl_char):\n",
    "    line[-6] = tpl\n",
    "\n",
    "# revert back to a space delimited file\n",
    "insfr = [' '.join(line) for line in insfr]\n",
    "\n",
    "# write out the TPL file\n",
    "with open(os.path.join(template_ws,'{}.tpl'.format(sfrfilename)), 'w') as ofp:\n",
    "    ofp.write('ptf ~\\n')\n",
    "    [ofp.write('{}\\n'.format(line)) for line in headerlines]\n",
    "    [ofp.write('{}\\n'.format(line)) for line in insfr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.add_parameters(os.path.join(template_ws,'{}.tpl'.format(sfrfilename)),  pst_path='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parval1 = pyemu.pst_utils.try_read_input_file_with_tpl(os.path.join(template_ws,'{}.tpl'.format(sfrfilename)),\n",
    "                                                 os.path.join(template_ws,sfrfilename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.parameter_data.loc[pst.parameter_data.parnme.str.startswith('sfr'),'pargp'] = 'sfrk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.parameter_data.loc[pst.parameter_data.parnme == 'sfrk_700039914']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add in the observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign meaningful observation values and prepare to run `noptmax=0` test run prior to reweighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_forward_run=True\n",
    "run_local=True\n",
    "update_all_obs = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### if `update_all_obs` is True, run the get_observations.py script to get a new INS file and reset all observations in the PEST object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if update_all_obs is True:\n",
    "    shutil.copy2('../scripts/get_observations.py',os.path.join(template_ws,'get_observations.py'))\n",
    "    shutil.copy2('../scripts/get_observations.py',os.path.join(sim_ws,'get_observations.py'))\n",
    "    \n",
    "    os.system('python {} {} True'.format(os.path.join(sim_ws,'get_observations.py'), sim_ws))\n",
    "    [shutil.copy2(cf, os.path.join(template_ws, os.path.basename(cf))) \n",
    "        for cf in glob.glob(os.path.join(sim_ws, '*.ins'))]\n",
    "    [shutil.copy2(cf, os.path.join(template_ws, os.path.basename(cf))) \n",
    "        for cf in glob.glob(os.path.join(sim_ws, 'land_*.csv'))]\n",
    "    \n",
    "    pst.observation_data.loc[:,:] = np.nan\n",
    "    pst.observation_data.dropna(inplace=True)\n",
    "    pst.add_observations(os.path.join(template_ws,'obs_mf6.dat.ins'), pst_path='.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  set the observation groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = pst.observation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs.obgnme = 'head'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs.loc[obs.index.str.startswith('q_'), 'obgnme'] = 'flux'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs.loc[obs.index.str.startswith('perc'), 'obgnme'] = 'budget'\n",
    "obs.loc[obs.index.str.startswith('land'), 'obgnme'] = 'land_surface'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set observation values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_obs = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if set_obs:\n",
    "    # read in sfr; make sfr obsnme/obsval dict to map to pst observation_data\n",
    "    sfr_df = pd.read_csv('../processed_data/NWIS_DV_STREAMSTATS_SITES.csv')\n",
    "    sfr_df['obsnme'] = 'q_' + sfr_df['site_id'].astype(str)\n",
    "    sfr_df['obsval'] = (sfr_df['Mean_Annual_Flow_cfs'] * sfr_df['Average_BFI_value']) * 2446.5755455 # convert from cfs to m^3/day\n",
    "    sfr_df[['obsnme', 'obsval']]\n",
    "    sfr_dict = pd.Series(sfr_df['obsval'].values,index=sfr_df['obsnme']).to_dict()\n",
    "    \n",
    "    # read in nwis heads; make nwis head obsnme/obsval dict\n",
    "    nwis_gw_df = pd.read_csv('../processed_data/NWIS_GW_DV_data.csv')\n",
    "    nwis_gw_df['obsnme'] = 'h_' + nwis_gw_df['site_no'].astype(str)\n",
    "    nwis_gw_df['obsval'] = nwis_gw_df['gw_elev_m']\n",
    "    nwis_gw_dict = pd.Series(nwis_gw_df['obsval'].values,index=nwis_gw_df['obsnme']).to_dict()\n",
    "    \n",
    "    # read in DEC heads; make DEC heads obsnme/obsval dict\n",
    "    DEC_gw_df = pd.read_csv('../processed_data/NY_DEC_GW_sites.csv')\n",
    "    DEC_gw_df['obsnme'] = ('h_' + DEC_gw_df['WellNO'].astype(str)).str.lower()\n",
    "    DEC_gw_df['obsval'] = DEC_gw_df['gw_elev_m']\n",
    "    DEC_gw_dict = pd.Series(DEC_gw_df['obsval'].values,index=DEC_gw_df['obsnme']).to_dict()\n",
    "    \n",
    "    # map SFR values to observation_data\n",
    "    obs.loc[obs.obsnme.isin(sfr_dict.keys()), 'obsval'] = obs.obsnme.map(sfr_dict)\n",
    "    \n",
    "    # map nwis heads to observation_data\n",
    "    obs.loc[obs.obsnme.isin(nwis_gw_dict.keys()), 'obsval'] = obs.obsnme.map(nwis_gw_dict)\n",
    "    \n",
    "    # map DEC heads to SRF observation_data\n",
    "    obs.loc[obs.obsnme.isin(DEC_gw_dict.keys()), 'obsval'] = obs.obsnme.map(DEC_gw_dict)\n",
    "    \n",
    "    # set up percent discrepancy as dummy value\n",
    "    obs.loc[obs.obgnme=='budget', 'obsval'] = -99999\n",
    "    \n",
    "    # get the land surface obs\n",
    "    lsobs_df = pd.read_csv('../neversink_mf6/land_surf_obs-observations.csv', index_col=0)\n",
    "    \n",
    "    obs.loc[obs.obgnme=='land_surface', 'obsval'] = lsobs_df.obsval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### first cut at weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs.loc[obs.obsnme=='q_1436500', 'weight'] = 3.33/obs.loc[obs.obsnme=='q_1436500'].obsval\n",
    "obs.loc[obs.obsnme=='q_1366650', 'weight'] = 10/obs.loc[obs.obsnme=='q_1366650'].obsval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs.loc[obs.obgnme=='head', 'weight'] = 1/5\n",
    "obs.loc[obs.obgnme=='land_surface', 'weight'] = 1/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs.loc[obs.obgnme=='budget', 'weight'] = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## update some parameter bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pars = pst.parameter_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-zones set to not get too crazy high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  read in k value lookup table to df\n",
    "\n",
    "#  original table\n",
    "\n",
    "k_df_original = pd.read_excel(\n",
    "    '../processed_data/Rondout_Neversink_GeologyLookupTable.xlsx',\n",
    "    sheet_name='Sheet2'\n",
    ")\n",
    "k_df_original.index = k_df_original.Lookup_Code\n",
    "\n",
    "k_df = pd.read_excel(\n",
    "    '../processed_data/Rondout_Neversink_GeologyLookupTable_jhw.xlsx',\n",
    "    sheet_name='Sheet2'\n",
    ")\n",
    "\n",
    "k_df.index = k_df.Lookup_Code\n",
    "\n",
    "print('Using mean K value')\n",
    "k_df['Kh_ft_d_mean'] = (k_df['Kh_ft_d_lower'] + k_df['Kh_ft_d_upper']) / 2\n",
    "k_df['Kh_m_d'] = k_df['Kh_ft_d_mean'] * 0.3048\n",
    "    \n",
    "k_df['Kh_m_d_lower'] = k_df['Kh_ft_d_lower'] * .3048\n",
    "k_df['Kh_m_d_upper'] = k_df['Kh_ft_d_upper'] * .3048\n",
    "\n",
    "k_df['K_upper_mult'] = k_df['Kh_m_d_upper'] / k_df['Kh_m_d']\n",
    "k_df['K_lower_mult'] = k_df['Kh_m_d_lower'] / k_df['Kh_m_d']\n",
    "\n",
    "\n",
    "k_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_mult_zones = [int(i.split(':')[-1]) for i in pars.loc[pars.parnme.str.startswith('multiplier_k')].index]\n",
    "np.unique(k_mult_zones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_mults = [k_df.loc[i].K_upper_mult for i in k_mult_zones]\n",
    "lower_mults = [k_df.loc[i].K_lower_mult for i in k_mult_zones]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pars.loc[pars.parnme.str.startswith('multiplier_k'), 'parlbnd'] = lower_mults\n",
    "pars.loc[pars.parnme.str.startswith('multiplier_k'), 'parubnd'] = upper_mults\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pilot points set to mean upper and lower bounds diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_lower = k_df.K_lower_mult.mean()\n",
    "mean_upper = k_df.K_upper_mult.mean()\n",
    "mean_lower,mean_upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pars.loc[pars.pargp.str.startswith('k'), 'parlbnd'] = mean_lower + 0.01\n",
    "pars.loc[pars.pargp.str.startswith('k'), 'parubnd'] = mean_upper - 0.01\n",
    "pars.loc[pars.pargp.str.startswith('sfrk'), 'parlbnd'] = 0.1\n",
    "pars.loc[pars.pargp.str.startswith('sfrk'), 'parubnd'] = 10.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set CHD parameters to 'fixed'. They will not be estimated, but are present to evaluate in global sensitivity analysis which means we will free them only for that purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pars.loc[pars.pargp=='chd', 'partrans'] = 'fixed'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `pyemu` can write out a summary file with summary of the parameterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsum = pst.write_par_summary_table('../report_materials/initial_parsum.xlsx', report_in_linear_space=True)\n",
    "parsum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## update the forward run to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note there are ways to do this within PstFrom but we were unaware of that when we set this up\n",
    "# note also we are putting the model run and postprocessing lines just above if __name__ == \"__main__\" line\n",
    "frunlines = open(os.path.join(template_ws, 'forward_run.py'), 'r').readlines()\n",
    "if update_forward_run is True and './mf6' not in ' '.join([i.strip() for i in frunlines]):\n",
    "    print('updating forward_run.py')\n",
    "    with open(os.path.join(template_ws, 'forward_run.py'), 'w') as ofp:\n",
    "        for line in frunlines:\n",
    "            if '__main__' in line:\n",
    "                ofp.write(\"    os.system('./mf6')\\n\")\n",
    "                ofp.write(\"    os.system('python get_observations.py . false')\\n\")\n",
    "                ofp.write('{}\\n'.format(line)) \n",
    "            elif 'import os' in line:\n",
    "                ofp.write('import os, sys\\n')\n",
    "                ofp.write(\"sys.path.append('../python_packages_static/')\\n\")\n",
    "            else:\n",
    "                ofp.write(line)          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set noptmax = 0 and a couple ++ options and write out PST file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.pestpp_options[\"ies_num_reals\"] = 500  \n",
    "pst.pestpp_options[\"ies_bad_phi_sigma\"] = 2\n",
    "pst.pestpp_options[\"overdue_giveup_fac\"] = 4\n",
    "pst.pestpp_options[\"ies_save_rescov\"] = True\n",
    "pst.pestpp_options[\"ies_no_noise\"] = True\n",
    "pst.pestpp_options[\"ies_drop_conflicts\"] = True\n",
    "pst.pestpp_options[\"ies_pdc_sigma_distance\"] = 2.0\n",
    "pst.control_data.noptmax = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### write out the PST file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.write(os.path.join(template_ws,'prior_mc.pst'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# copy over the entire pest directory to a separate folder identified by the `noptmax0_dir` variable. This is to keep the `emplate_ws` clean and allow for various testing to take place int he `noptmax0_dir` location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(noptmax0_dir):\n",
    "    shutil.rmtree(noptmax0_dir)\n",
    "shutil.copytree(template_ws, noptmax0_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.write_obs_summary_table('../report_materials/obs_initial.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If running on Windows, remove backslashes from `mult2model_info.csv` for running on linux cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sys.platform == 'win32':\n",
    "    f = open(os.path.join(template_ws, 'mult2model_info.csv'), \"r\")\n",
    "    lines = f.readlines()\n",
    "    f.close()\n",
    "\n",
    "    output_lines = []\n",
    "    for line in lines:\n",
    "        output_lines.append(line.replace('\\\\', \"/\"))\n",
    "\n",
    "    f = open(os.path.join(template_ws, 'mult2model_info.csv'), \"w\")\n",
    "    f.write(''.join(output_lines))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### and the pest file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sys.platform == 'win32':\n",
    "    f = open(os.path.join(template_ws, 'prior_mc.pst'), \"r\")\n",
    "    lines = f.readlines()\n",
    "    f.close()\n",
    "\n",
    "    output_lines = []\n",
    "    for line in lines:\n",
    "        output_lines.append(line.replace('\\\\', \"/\"))\n",
    "\n",
    "    f = open(os.path.join(template_ws, 'prior_mc.pst'), \"w\")\n",
    "    f.write(''.join(output_lines))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### and update the forward run command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sys.platform == 'win32':\n",
    "    f = open(os.path.join(template_ws, 'forward_run.py'), \"r\")\n",
    "    lines = f.readlines()\n",
    "    f.close()\n",
    "\n",
    "    output_lines = []\n",
    "    for line in lines:\n",
    "        output_lines.append(line.replace('./mf6', \"mf6\"))\n",
    "\n",
    "    # fix in run_dir \n",
    "    f = open(os.path.join(template_ws, 'forward_run.py'), \"w\")\n",
    "    f.write(''.join(output_lines))\n",
    "    f.close()\n",
    "    \n",
    "    # fix in noptmax_0_testing\n",
    "    f = open(os.path.join(noptmax0_dir, 'forward_run.py'), \"w\")\n",
    "    f.write(''.join(output_lines))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
