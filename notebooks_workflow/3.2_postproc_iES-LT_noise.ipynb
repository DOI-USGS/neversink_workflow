{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../python_packages_static/')\n",
    "import pandas as pd\n",
    "import pyemu\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os, glob, shutil\n",
    "import geopandas as gp\n",
    "import datetime as dt\n",
    "import flopy as fp\n",
    "from shapely.geometry import Point\n",
    "from matplotlib.backends.backend_pdf import PdfPages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Postprocessing of iES runs. There are two key decisions to make. Which iteration is the best (subjective) tradeoff between fit and variance in the ensemble and, given a chosen iteration, what is an appropriate cutoff for rejection sampling. These decisions lead to visualization of the observation fits and generation of the ensemble to be used with MODPATH for the source water area delineation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rundir = '../run_data'                # directory in which runs took place\n",
    "pstroot = 'never_ies_0.noise_lt_obs'  # PST file root for iES\n",
    "outfolder = '{}/postproc/'.format(rundir)  # write out output files to this location\n",
    "obs_data = '../obs_data'\n",
    "drop_pdc = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the Phi of the whole ensemble as it evolves over the iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi = pd.read_csv(os.path.join(rundir,\"{}.phi.actual.csv\".format(pstroot)),index_col=0)\n",
    "plt.figure(figsize=rf.doublecolumn_size)\n",
    "ax = phi['base'].apply(np.log10).plot(legend=False, lw=1.5, color='r', label='base')\n",
    "phi.iloc[:,6:7].apply(np.log10).plot(legend=False,lw=0.5,color='k',alpha=0.15,label='realizations', ax = ax)\n",
    "plt.legend(['base','realizations'])\n",
    "phi.iloc[:,6:].apply(np.log10).plot(legend=False,lw=0.5,alpha=0.15,color='k', ax = ax)\n",
    "phi['base'].apply(np.log10).plot(legend=False, lw=1.5, color='r', ax=ax)\n",
    "plt.ylabel('log Phi')\n",
    "plt.xlabel('iES iteration')\n",
    "plt.xticks(ticks=np.arange(10))\n",
    "ax.axes.tick_params(length=7, direction='in', right=True, top=True)\n",
    "plt.legend(['base','realizations'], title='EXPLANATION', frameon=False, bbox_to_anchor =(0.97, 0.95))\n",
    "plt.savefig('../report_materials/phi_history_iES.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a `bounds_report` helps visualize, for the base realization, how many parameters were at their bounds. This can help guide the decision of whether iterations are overfit or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pst.bounds_report()\n",
    "df_tot =  df[[i for i in df.columns if 'either' in i]].loc['total'].copy()\n",
    "df_tot.index = [int(i.split('_')[-1]) for i in df_tot.index]\n",
    "df_tot.plot()\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('total at bounds')\n",
    "plt.grid()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we are choosing iteration 4 as best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_iter = 4\n",
    "pst = pyemu.Pst('{0}/{1}.pst'.format(rundir, pstroot), \n",
    "                resfile=os.path.join(rundir,'{}.{}.base.rei'.format(pstroot,best_iter)))\n",
    "obs=pst.observation_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we can make a quick 1to1 plot of the base ensemble member"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.plot(kind='1to1', filename='{0}/{1}.{2}_iter_{3}.pdf'.format(outfolder, pstroot, '.base.1to1', best_iter))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### here we decide whether or not we will visualize results which were in prior data conflict (PDC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if drop_pdc is True:\n",
    "    # read in the PDC list of values\n",
    "    pdc = pd.read_csv(os.path.join(rundir,'{}.pdc.csv'.format(pstroot)))\n",
    "    pdc.name = pdc.name.apply(lambda x: x.lower())\n",
    "    # zero weight all the PDC values\n",
    "    obs.loc[pdc.name.values, 'weight'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot residuals only for nonzero weight for the base realization which is read in automatically when `pyemu` reads in the pst control file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(np.unique(pst.res.index == obs.index))==np.array(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpres = pst.res.copy()\n",
    "tmpres.weight = obs.weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpres = tmpres.loc[pst.res.weight>0]\n",
    "print(len(tmpres))\n",
    "tmpres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cn,cg in tmpres.groupby('group'):\n",
    "    fig, ax = plt.subplots(1,2, figsize=(8,4))\n",
    "    ax[0].plot([0, 1], [0, 1],'--',transform=ax[0].transAxes)\n",
    "    ax[0].scatter(cg.measured,cg.modelled, s=10)\n",
    "    ax[0].set_xlabel('measured')\n",
    "    ax[0].set_ylabel('modeled')\n",
    "    ax[0].set_title('1to1')\n",
    "    #ax[0].set_aspect('equal')\n",
    "    ax[1].scatter(cg.measured, cg.residual, s=10)\n",
    "    xlim = ax[1].get_xlim()\n",
    "    ax[1].plot(xlim, [0,0], '--')\n",
    "    ax[1].plot(xlim, [cg.residual.mean(),cg.residual.mean()], 'r-', lw=2)\n",
    "    ax[1].set_title('residuals')\n",
    "    plt.suptitle(cn)\n",
    "    ax[1].set_xlabel('measured')\n",
    "    ax[1].set_ylabel('residual')\n",
    "    #ax[1].set_aspect('square')\n",
    "    #plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rejection Sampling. We can look at the PHI histogram for the best iteration and assign a cutoff of `phi_too_high` which delineates where rejection takes place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phivec = phi.loc[best_iter][5:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phivec.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_too_high= 3200 # was previously 5500 on 11/2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the next couple cells seem extra involved, but they are meant to make fancy figures for the journal; article showing PHI evolution over iterations and the rejection sampling all together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_subplot_axes(ax,rect,axisbg='w'):\n",
    "    fig = plt.gcf()\n",
    "    box = ax.get_position()\n",
    "    width = box.width\n",
    "    height = box.height\n",
    "    inax_position  = ax.transAxes.transform(rect[0:2])\n",
    "    transFigure = fig.transFigure.inverted()\n",
    "    infig_position = transFigure.transform(inax_position)    \n",
    "    x = infig_position[0]\n",
    "    y = infig_position[1]\n",
    "    width *= rect[2]\n",
    "    height *= rect[3]  # <= Typo was here\n",
    "    subax = fig.add_axes([x,y,width,height])\n",
    "    x_labelsize = subax.get_xticklabels()[0].get_size()\n",
    "    y_labelsize = subax.get_yticklabels()[0].get_size()\n",
    "    x_labelsize *= rect[2]**0.5\n",
    "    y_labelsize *= rect[3]**0.5\n",
    "    subax.xaxis.set_tick_params(labelsize=x_labelsize)\n",
    "    subax.yaxis.set_tick_params(labelsize=y_labelsize)\n",
    "    return subax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5,4))\n",
    "ax = phi['base'].apply(np.log10).plot(legend=False, lw=1.5, color='b', label='base')\n",
    "phi.iloc[:,6:7].apply(np.log10).plot(legend=False,lw=0.5,color='k',alpha=0.15,label='realizations', ax = ax)\n",
    "plt.legend(['base','realizations'])\n",
    "phi.iloc[:,6:].apply(np.log10).plot(legend=False,lw=0.5,alpha=0.15,color='k', ax = ax)\n",
    "phi['base'].apply(np.log10).plot(legend=False, lw=1.5, color='b', ax=ax)\n",
    "plt.ylabel('log $\\Phi$')\n",
    "\n",
    "ax1 = add_subplot_axes(ax, [0.5,.32,.4,0.4])\n",
    "ax1.axvline(phi_too_high, color='k', label='cutoff $\\Phi$')\n",
    "ax1.legend()\n",
    "phivec = phi.loc[best_iter][5:].copy()\n",
    "phivec.hist(bins=50, ax=ax1)\n",
    "rf.title(ax,'Log $\\Phi$ over iES iterations', capitalize=False, subplot_prefix='A')\n",
    "rf.title(ax1,'Iteration 4 $\\Phi$ histogram with rejection cutoff', wrap=39, capitalize=False, subplot_prefix='B')\n",
    "\n",
    "#plt.savefig('phi_and_rejection.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phivec = phi.loc[best_iter][5:].copy()\n",
    "fig, ax = plt.subplots(1,2, figsize=(rf.doublecolumn_size))\n",
    "phivec.hist(bins=50, ax=ax[0])\n",
    "ax[0].axvline(phi_too_high, color='k', label='cutoff PHI')\n",
    "ax[0].legend()\n",
    "ax[0].set_ylabel('Frequency')\n",
    "print(len(phivec))\n",
    "phivec = phivec[phivec<phi_too_high]\n",
    "print(len(phivec))\n",
    "phivec.hist(bins=50, ax=ax[1])\n",
    "ax[1].set_xlim(ax[0].get_xlim())\n",
    "ax[0].set_xlabel('Realization PHI')\n",
    "ax[1].set_xlabel('Realization PHI')\n",
    "rf.title(ax[0],'PHI distribution', capitalize=False, subplot_prefix='A')\n",
    "rf.title(ax[1],'PHI distribution trimmed', capitalize=False, subplot_prefix='B')\n",
    "\n",
    "handles, labels = ax[0].get_legend_handles_labels()\n",
    "rf.legend(ax[0], handles, labels, bbox_to_anchor=(.8, 0.85))\n",
    "\n",
    "\n",
    "#plt.savefig('../report_materials/Figure20_rejectionsampling.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now we need to make a `reals_to_keep` vector that keeps track of the ensemble members that made it through rejection sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reals_to_keep = phivec.index.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### in early stages of the project, there were cases where some model results with reasonable PHI had poor mass balance, so we rejected them as well. Now that is not a problem, but the logic is shown here nonetheless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# truncate the ensemble to only reals_to_keep (based on phi)\n",
    "ens = pd.read_csv(os.path.join(rundir,'{}.0.obs.csv'.format(pstroot)), index_col=0)\n",
    "\n",
    "ens = ens.loc[reals_to_keep]\n",
    "# set percent_discrepancy to absolute value because we don't care about the sign\n",
    "ens.perc_disc = ens.perc_disc.apply(lambda x: np.abs(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# further truncate to eliminate bad mass balance runs \n",
    "print(len(ens))\n",
    "ens = ens.loc[ens.perc_disc<0.01]\n",
    "ens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens.perc_disc.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of zero-weighted values dropped in the PDC\n",
    "ens = ens[tmpres.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset keepreals based now both on phi and mass balance\n",
    "reals_to_keep = ens.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phivec = phivec.loc[reals_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phivec.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_ens = pd.read_csv(os.path.join(rundir,'{}.0.obs.csv'.format(pstroot)), index_col=0)\n",
    "base_ens = base_ens.loc[reals_to_keep]\n",
    "base_ens = base_ens[tmpres.index]\n",
    "pyemu.plot_utils.ensemble_res_1to1(ens, pst, base_ensemble=base_ens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdc = pd.read_csv(os.path.join(rundir,'{}.pdc.csv'.format(pstroot)))\n",
    "pdc.name = pdc.name.apply(lambda x: x.lower())\n",
    "pdc.set_index('name', inplace=True, drop=True)\n",
    "pdc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot without PDC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_pdc = [i for i in pdc.index if not i.startswith('q_')] # make sure we still plot streamflow even if in PDC. \n",
    "        # should not be the case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens = ens[[i for i in ens.columns if i not in drop_pdc]]\n",
    "base_ens = base_ens[[i for i in ens.columns if i not in drop_pdc]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we can save out this observation ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens.to_csv('../notebooks_report/final_obs_ensembles/ies_post_lt_noise.obs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpres = tmpres.loc[[i for i in ens.columns if i not in drop_pdc]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_ens = pd.read_csv(os.path.join(rundir,'{}.obs+noise.csv'.format(pstroot)), index_col=0)\n",
    "obs_ens = obs_ens.loc[reals_to_keep]\n",
    "obs_ens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this case, with sampling of observation noise, looking for overlap of distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with PdfPages(os.path.join(rundir, 'postproc','{}_trimmed_pdc_obs_hist_plots.pdf'.format(pstroot))) as outpdf:\n",
    "    for cob in tmpres.index.values:\n",
    "        plt.figure()\n",
    "       \n",
    "        obs_ens[cob].hist(bins=50, color='orange', edgecolor='none', alpha=.7,label='observed')\n",
    "        ens[cob].hist(bins=50, edgecolor='none', label='modelled')\n",
    "        plt.axvline(obs_ens[cob].mean(), mfc='k', alpha=.5,label='obs mean')\n",
    "        plt.axvline(obs_ens[cob].mean()+obs_ens[cob].std(), mfc='k', ls=':', alpha=.5, label='obs + 1$\\sigma$')\n",
    "        plt.axvline(obs_ens[cob].mean()-obs_ens[cob].std(), mfc='k', ls=':', alpha=.5, label='obs - 1$\\sigma$')\n",
    "        \n",
    "        \n",
    "        plt.title(cob)\n",
    "        plt.legend()\n",
    "        outpdf.savefig()\n",
    "        plt.close('all')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finally, after all the visualization, we save out the paremeter ensemble to supply to MODPATH for the final source water area delineation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par_ens = pd.read_csv(os.path.join(rundir,'{0}.{1}.par.csv'.format(pstroot, best_iter)), index_col=0)\n",
    "par_ens.index = [str(i) for i in par_ens.index]\n",
    "par_ens = par_ens.loc[reals_to_keep]\n",
    "par_ens.to_csv(os.path.join(rundir, 'modpath_par_ens.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
